@page "/chat"
@using System.Text.Json
@using src.Data
@inject OllamaService OllamaService
@inject IJSRuntime JSRuntime
@inject ILogger<Chat> Logger

<PageTitle>Chat with LLM</PageTitle>

<h1>Chat with AI</h1>

<div class="chat-container">
    <div class="message-container">
        @foreach (var message in messages)
        {
            <div class="message @(message.IsUser ? "user-message" : "ai-message")">
                <div class="message-header">@(message.IsUser ? "You" : selectedModel)</div>
                 <div class="message-content">@((MarkupString)FormatMessage(message.Content))
                </div>
            </div>
        }
        @if (isGenerating)
        {
            <div class="message ai-message">
                <div class="message-header">@selectedModel</div>
                <div class="message-content">Thinking...</div>
            </div>
        }
    </div>

    <div class="input-container">
        <div class="model-selector-row">
        <div class="model-selector">
            <label for="model-select">Model:</label>
                <select id="model-select" @bind="selectedModel" @bind:after="SaveChatHistoryAsync" disabled="@isGenerating">
                @foreach (var model in availableModels)
                {
                    <option value="@model">@model</option>
                }
            </select>
        </div>

            <button class="clear-button" @onclick="ClearChatHistory" disabled="@(isGenerating || messages.Count == 0)">
                Clear Chat
            </button>
        </div>
        
        <textarea 
            @bind="userInput" 
            @onkeydown="HandleKeyDown"
            placeholder="Type your message here..." 
            disabled="@isGenerating"
            rows="3"
            class="input-textarea">
        </textarea>
        
        <button @onclick="SendMessage" disabled="@(isGenerating || string.IsNullOrWhiteSpace(userInput))">
            Send
        </button>
    </div>
</div>

<style>
    .chat-container {
        display: flex;
        flex-direction: column;
        height: 80vh;
        border: 1px solid #ccc;
        border-radius: 8px;
        overflow: hidden;
    }
    
    .message-container {
        flex: 1;
        overflow-y: auto;
        padding: 20px;
    }
    
    .message {
        margin-bottom: 15px;
        padding: 10px 15px;
        border-radius: 8px;
        max-width: 80%;
    }
    
    .user-message {
        background-color: #dcf8c6;
        margin-left: auto;
    }
    
    .ai-message {
        background-color: #f1f0f0;
        margin-right: auto;
    }
    
    .message-header {
        font-weight: bold;
        margin-bottom: 5px;
    }
    
    .message-content {
        white-space: pre-wrap;
        word-break: break-word;
    }
    
    .input-container {
        display: flex;
        flex-direction: column;
        padding: 15px;
        background-color: #f8f9fa;
        border-top: 1px solid #ccc;
    }
    
    .model-selector {
        margin-bottom: 10px;
    }
    
    .model-selector-row {
        display: flex;
        justify-content: space-between;
        align-items: center;
        margin-bottom: 10px;
    }

    .clear-button {
        background-color: #dc3545;
        padding: 4px 8px;
        font-size: 0.9rem;
    }

    .input-textarea {
        flex: 1;
        border: 1px solid #ccc;
        border-radius: 4px;
        padding: 8px;
        margin-bottom: 10px;
        resize: none;
    }
    
    button {
        background-color: #007bff;
        color: white;
        border: none;
        border-radius: 4px;
        padding: 8px 15px;
        cursor: pointer;
    }
    
    button:disabled {
        background-color: #cccccc;
    }
</style>

@code {
    private string userInput = "";
    private List<ChatMessage> messages = new();
    private bool isGenerating = false;
    private string selectedModel = "llama3";
    private List<string> availableModels = new() { "llama3" };
    
    private const string STORAGE_KEY = "chat_history";
    private const string MODEL_KEY = "selected_model";

    protected override async Task OnInitializedAsync()
    {
        Logger.LogTrace("OnInitializedAsync START");
        Logger.LogInformation("OnInitializedAsync called");
        try
        {
            var models = await OllamaService.ListModelsAsync();
            availableModels = models.Select(m => m.Name).ToList();
            Logger.LogTrace("Model list loaded: {Models}", string.Join(",", availableModels));
            Logger.LogInformation("Loaded {ModelCount} models", availableModels.Count);
            // Load saved model preference
            var savedModel = await LoadSelectedModelAsync();
            Logger.LogTrace("Loaded savedModel: {SavedModel}", savedModel);
            if (!string.IsNullOrEmpty(savedModel) && availableModels.Contains(savedModel))
            {
                selectedModel = savedModel;
                Logger.LogTrace("selectedModel set to savedModel: {Model}", selectedModel);
                Logger.LogInformation("Loaded saved model preference: {Model}", savedModel);
            }
            else if (availableModels.Count > 0 && !availableModels.Contains(selectedModel))
            {
                selectedModel = availableModels[0];
                Logger.LogTrace("selectedModel set to first available: {Model}", selectedModel);
                Logger.LogInformation("Defaulted to first available model: {Model}", selectedModel);
            }
            Logger.LogTrace("OnInitializedAsync END");
            await base.OnInitializedAsync();
        }
        catch (Exception ex)
        {
            Logger.LogError(ex, "Error loading models");
            Logger.LogTrace("OnInitializedAsync ERROR: {Error}", ex);
            Console.WriteLine($"Error loading models: {ex.Message}");
        }
    }
    
    private bool _isFirstRender = true;

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        Logger.LogTrace("OnAfterRenderAsync called, firstRender={FirstRender}", firstRender);
        if (firstRender)
        {
            _isFirstRender = false;
            Logger.LogTrace("_isFirstRender set to false");
            Logger.LogInformation("OnAfterRenderAsync first render");
            // Load saved model preference
            var savedModel = await LoadSelectedModelAsync();
            Logger.LogTrace("Loaded savedModel: {SavedModel}", savedModel);
            if (!string.IsNullOrEmpty(savedModel) && availableModels.Contains(savedModel))
            {
                selectedModel = savedModel;
                Logger.LogTrace("selectedModel set to savedModel: {Model}", selectedModel);
                Logger.LogInformation("Restored saved model preference: {Model}", savedModel);
            }
            // Load saved chat history
            await LoadChatHistoryAsync();
            Logger.LogTrace("Chat history loaded, messages.Count={Count}", messages.Count);
            Logger.LogInformation("Loaded chat history with {MessageCount} messages", messages.Count);
            StateHasChanged();
            Logger.LogTrace("StateHasChanged called after first render");
        }
        await base.OnAfterRenderAsync(firstRender);
    }
    
    private async Task LoadChatHistoryAsync()
    {
        Logger.LogTrace("LoadChatHistoryAsync called");
        try
        {
            var json = await JSRuntime.InvokeAsync<string>("localStorage.getItem", STORAGE_KEY);
            Logger.LogTrace("localStorage.getItem returned: {Json}", json);
            if (!string.IsNullOrEmpty(json))
            {
                messages = JsonSerializer.Deserialize<List<ChatMessage>>(json) ?? new List<ChatMessage>();
                Logger.LogTrace("Deserialized messages: {Messages}", string.Join("|", messages.Select(m => m.Content)));
                Logger.LogInformation("Loaded chat history from storage: {MessageCount} messages", messages.Count);
            }
            else
            {
                Logger.LogTrace("No chat history found in storage");
                Logger.LogInformation("No chat history found in storage");
            }
        }
        catch (Exception ex)
        {
            Logger.LogError(ex, "Error loading chat history");
            Logger.LogTrace("LoadChatHistoryAsync ERROR: {Error}", ex);
            Console.WriteLine($"Error loading chat history: {ex.Message}");
        }
    }
    
    private async Task SaveChatHistoryAsync()
    {
        Logger.LogTrace("SaveChatHistoryAsync called");
        try
        {
            var json = JsonSerializer.Serialize(messages);
            Logger.LogTrace("Serialized messages: {Json}", json);
            await JSRuntime.InvokeVoidAsync("localStorage.setItem", STORAGE_KEY, json);
            Logger.LogTrace("localStorage.setItem for chat history complete");
            Logger.LogInformation("Saved chat history: {MessageCount} messages", messages.Count);
            // Save selected model as well
            await JSRuntime.InvokeVoidAsync("localStorage.setItem", MODEL_KEY, selectedModel);
            Logger.LogTrace("localStorage.setItem for selected model complete: {Model}", selectedModel);
            Logger.LogInformation("Saved selected model: {Model}", selectedModel);
        }
        catch (Exception ex)
        {
            Logger.LogError(ex, "Error saving chat history");
            Logger.LogTrace("SaveChatHistoryAsync ERROR: {Error}", ex);
            Console.WriteLine($"Error saving chat history: {ex.Message}");
        }
    }
    
    private async Task<string> LoadSelectedModelAsync()
    {
        Logger.LogTrace("LoadSelectedModelAsync called");
        try
        {
            var model = await JSRuntime.InvokeAsync<string>("localStorage.getItem", MODEL_KEY);
            Logger.LogTrace("localStorage.getItem for model returned: {Model}", model);
            Logger.LogInformation("Loaded selected model from storage: {Model}", model);
            return model;
        }
        catch (Exception ex)
        {
            Logger.LogError(ex, "Error loading selected model");
            Logger.LogTrace("LoadSelectedModelAsync ERROR: {Error}", ex);
            return string.Empty;
        }
    }

    private async Task SendMessage()
    {
        Logger.LogTrace("SendMessage called");
        if (string.IsNullOrWhiteSpace(userInput) || isGenerating)
        {
            Logger.LogTrace("SendMessage early exit: userInput empty or isGenerating");
            return;
        }
        Logger.LogInformation("User sending message: {Message}", userInput);
        // Add user message
        var userMessage = new ChatMessage { Content = userInput, IsUser = true };
        messages.Add(userMessage);
        Logger.LogTrace("User message added: {Message}", userInput);
        string currentInput = userInput;
        userInput = "";
        isGenerating = true;
        Logger.LogTrace("isGenerating set to true");
        StateHasChanged();
        Logger.LogTrace("StateHasChanged called after user message");
        try
        {
            // Get AI response
            var response = await OllamaService.ChatAsync(currentInput, selectedModel);
            Logger.LogInformation("AI responded with {Length} characters", response?.Length ?? 0);
            Logger.LogTrace("AI response: {Response}", response);
            // Add AI message
            messages.Add(new ChatMessage { Content = response ?? string.Empty, IsUser = false });
            Logger.LogTrace("AI message added");
            // Save the updated chat history
            await SaveChatHistoryAsync();
            Logger.LogTrace("Chat history saved after AI response");
        }
        catch (Exception ex)
        {
            Logger.LogError(ex, "Error during chat send");
            Logger.LogTrace("SendMessage ERROR: {Error}", ex);
            // Add error message
            messages.Add(new ChatMessage { 
                Content = $"Error: {ex.Message}", 
                IsUser = false 
            });
            Logger.LogTrace("Error message added to chat");
            // Save even if there was an error
            await SaveChatHistoryAsync();
            Logger.LogTrace("Chat history saved after error");
        }
        finally
        {
            isGenerating = false;
            Logger.LogTrace("isGenerating set to false");
            StateHasChanged();
            Logger.LogTrace("StateHasChanged called after send complete");
        }
    }
    // Add a method to clear chat history
    private async Task ClearChatHistory()
    {
        Logger.LogTrace("ClearChatHistory called");
        Logger.LogInformation("Clearing chat history");
        messages.Clear();
        Logger.LogTrace("messages cleared");
        await SaveChatHistoryAsync();
        Logger.LogTrace("Chat history saved after clear");
        StateHasChanged();
        Logger.LogTrace("StateHasChanged called after clear");
    }

    private void HandleKeyDown(KeyboardEventArgs e)
    {
        Logger.LogTrace("HandleKeyDown called: Key={Key}, Ctrl={Ctrl}", e.Key, e.CtrlKey);
        if (e.Key == "Enter" && e.CtrlKey)
        {
            Logger.LogTrace("Ctrl+Enter detected, calling SendMessage");
            _ = SendMessage();
        }
    }

    private string FormatMessage(string content)
    {
        Logger.LogTrace("FormatMessage called");
        // Simple conversion of newlines to <br> and preserving spaces
        return content
            .Replace("\n", "<br>")
            .Replace("  ", "&nbsp;&nbsp;");
    }

    public class ChatMessage
    {
        public string Content { get; set; } = "";
        public bool IsUser { get; set; }
    }
}